---
id: 41
title: 'ML Club Video: Dimensionality Reduction'
date: '2023-11-18T23:12:31+00:00'

layout: post
guid: 'http://karthikvedula.com/?p=41'
permalink: /2023/11/18/ml-club-video-dimensionality-reduction/
categories:
    - 'Machine Learning'
    - 'ML Club'
tags:
    - 'Dimensionality Reduction'
    - 'Machine Learning'
    - 'Principal Component Analysis'
    - t-SNE
---

<iframe allow="autoplay" height="480" loading="lazy" src="https://drive.google.com/file/d/1pFSbEyLe64mXvXm3CLhUp2utG7P106Nl/preview" width="640"></iframe>In this ML Club session, we’ll learn how to visualize 1000-dimensional data!

High dimensional data is everywhere!

How do we do this? We have to represent a 1000 dimensions in 2 dimensions such that the meaning of the data is still preserved. In the session we talk about two very different approaches – Principal Component Analysis and t-Distributed Stochastic Neighbor Embedding.

How do these approaches work? Watch the video to find out!
